{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X7ZwNViRWmT"
      },
      "source": [
        "# CC5215: Privacidad de Datos\n",
        "\n",
        "## Laboratorio 7\n",
        "\n",
        "Integrantes: (trabajé solo porque no pude conseguir un compañero de equipo)\n",
        "\n",
        "- Nombre: Diego Espinoza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9JmjcAJRRWmW"
      },
      "outputs": [],
      "source": [
        "# Load the data and libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def laplace_mech(v, sensitivity, epsilon):\n",
        "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
        "\n",
        "def pct_error(orig, priv):\n",
        "    return np.abs(orig - priv)/orig * 100.0\n",
        "\n",
        "barbie_ratings = pd.read_csv('https://users.dcc.uchile.cl/~darquez/barbie_ratings.csv')\n",
        "\n",
        "# YOU MAY USE THIS VARIABLES LATER\n",
        "ratings = barbie_ratings['rating']\n",
        "weights = barbie_ratings['weight']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xGQeIFqjtjv"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this lab we will work with a dataset of user ratings for the Barbie movie. In particular, we will try out different methods of making a weighted average of the ratings private."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0bgPBSKakOmZ",
        "outputId": "81afe092-35b3-4755-e605-88ed12ee1d98"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"barbie_ratings\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7,\n          10,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "barbie_ratings"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7595c436-89d1-450e-8079-f2a2d43ee15e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7595c436-89d1-450e-8079-f2a2d43ee15e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7595c436-89d1-450e-8079-f2a2d43ee15e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7595c436-89d1-450e-8079-f2a2d43ee15e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82675b2b-4dd1-4094-81ab-ee86931fb8aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82675b2b-4dd1-4094-81ab-ee86931fb8aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82675b2b-4dd1-4094-81ab-ee86931fb8aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   rating  weight\n",
              "0       4       2\n",
              "1      10       1\n",
              "2       5       4\n",
              "3       6       2\n",
              "4       5       2"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "barbie_ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UinIBswF7tMT"
      },
      "source": [
        "The dataset `barbie_ratings` has two columns: (1) `rating` which correspond to a rating given by a particular viewer, between 1 and 10; and (2) `weight` which corresponds to the importance of the given rating, between 1 and 4, based on previous data about the user (usefulness of other ratings, peer-voting, etc).\n",
        "\n",
        "**IMPORTANT: Through this lab, it is not necessary that you manually clip the data to the aforementioned bounds. The data is already compliant with the bounds.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HECMFt9fspPk"
      },
      "outputs": [],
      "source": [
        "## You may use this variables later:\n",
        "\n",
        "# Upper bound for ratings\n",
        "u = 10\n",
        "\n",
        "# Upper bound for weights\n",
        "wu = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hroFPGc1iYAv"
      },
      "source": [
        "## Question 1 (4 points)\n",
        "\n",
        "The weighted average formula is defined as:\n",
        "\n",
        "$$\n",
        "\\frac{\\sum_{i=1}^n w_i * x_i}{\\sum_{i=1}^n w_i}\n",
        "$$\n",
        "\n",
        "Where $w_i$ and $x_i$ in the ratings dataset corresponds to the the weight and rating of viewer $i$ respectively.\n",
        "(Notice that when all the weights $w_i$ are $1$, the weighted average is equivalent to the regular average)\n",
        "\n",
        "**Write a function that calculates the weighted average of a dataset**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13629"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O3D3wSd3l2a_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.484507042253521"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def weighted_avg(data, weights):\n",
        "    \"\"\"\n",
        "        Parameters:\n",
        "            data (pd.Series): The data to average\n",
        "            weights (pd.Series): The weights to calculate the average\n",
        "        Returns:\n",
        "            The `weights`-weighted average of `data`\n",
        "    \"\"\"\n",
        "    numerador = (data*weights).sum()\n",
        "    denominador = weights.sum()\n",
        "    promedio = numerador / denominador \n",
        "    return promedio\n",
        "\n",
        "weighted_avg(ratings, weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55XNs0SBmYI9"
      },
      "source": [
        "## Question 2 (6 points)\n",
        "\n",
        "Write a differentially private version of `weighted_avg`, using global sensitivity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QuH0cSQNm6H5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.92946307776455"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def laplace_noise(scale):\n",
        "    return np.random.laplace(loc=0.0, scale=scale)\n",
        "\n",
        "def gs_weighted_avg(data, weights, data_ub, weight_ub, epsilon):\n",
        "    \"\"\"\n",
        "        Parameters:\n",
        "            data (pd.Series): The data to average\n",
        "            weights (pd.Series): The weights to calculate the average\n",
        "            data_ub (int): Upper bound of the data values\n",
        "            weight_ub (int): Upper bound of the weights\n",
        "            epsilon (float): Privacy budget (must be > 0)\n",
        "        Returns:\n",
        "           Differentially private weighted average using global sensitivity\n",
        "    \"\"\"\n",
        "    if epsilon <= 0:\n",
        "        raise ValueError(\"Epsilon must be > 0 for differential privacy\")\n",
        "\n",
        "    data_clipped = data.clip(upper=data_ub)\n",
        "    weights_clipped = weights.clip(upper=weight_ub)\n",
        "\n",
        "    numerador = (data_clipped * weights_clipped).sum()\n",
        "    denominador = weights_clipped.sum()\n",
        "\n",
        "    #si cambiamos data solo un registro, la sensibilidad dice que\n",
        "    #el numerador cambiará en exactamente uno multiplicado por\n",
        "    #el peso (porque en el numerador se multiplican). \n",
        "    sens_numerador = data_ub * weight_ub\n",
        "    #mientras que la sensibilidad del denominador no cambia sustancialmente (a lo más \n",
        "    # en el upper bound del peso).\n",
        "    sens_denominador = weight_ub\n",
        "\n",
        "    #dividimos el presupuesto entre el cálculo del numerador y del denominador\n",
        "    epsilon_n = epsilon / 2\n",
        "    epsilon_d = epsilon / 2\n",
        "\n",
        "    numerador_ruidoso = numerador + laplace_noise(sens_numerador / epsilon_n)\n",
        "    denominador_ruidoso = denominador + laplace_noise(sens_denominador / epsilon_d)\n",
        "\n",
        "    return numerador_ruidoso / denominador_ruidoso\n",
        "\n",
        "\n",
        "gs_weighted_avg(ratings, weights, u, wu, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnont5rkm92c"
      },
      "source": [
        "**Explain why your implementation is `epsilon`-DP**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWjaE-79nIWw"
      },
      "source": [
        "YOUR ANSWER\n",
        "\n",
        "Cada una de las dos sumas tiene ruido calibrado para cumplir \n",
        "$\\varepsilon_n$-DP y $\\varepsilon_d$-DP respectivamente.\n",
        "\n",
        "Como ambas partes de la función (es decir, el numerador como el denominador) operan sobre el mismo conjunto de datos original, podemos aplicar composición secuencial:\n",
        "$$\n",
        "f(D) = \\frac{f_1(D) + \\text{Lap}(\\Delta_1 / \\varepsilon_n)}{f_2(D) + \\text{Lap}(\\Delta_2 / \\varepsilon_d)} \\Rightarrow \\text{es } (\\varepsilon_n + \\varepsilon_d)\\text{-DP}\n",
        "$$\n",
        "pero como dividimos el presupuesto $\\epsilon$ equitativamente entre $\\varepsilon_n$ y $\\varepsilon_d$, podemos decir que la función ´gs_weighted_avg´ es $(\\varepsilon_n + \\varepsilon_d)\\text{-DP}$ o $(\\varepsilon)\\text{-DP}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUogUQ8joWFH"
      },
      "source": [
        "## Question 3 (6 points)\n",
        "\n",
        "Calculate the local sensitivity of the weighted average.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAwP4fI2pDxB"
      },
      "source": [
        "YOUR ANSWER:\n",
        "\n",
        "(Complete the following)\n",
        "\n",
        "Given\n",
        "$$\n",
        "f(x, w) = \\frac{\\sum_{i=1}^n w_i * x_i}{\\sum_{i=1}^n w_i}\n",
        "$$\n",
        "\n",
        "If we add a row:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "|f(x, w) - f(x', w')| &= |   \\frac{\\sum_{i=1}^n w_i * x_i}{\\sum_{i=1}^n w_i} -          \\frac{\\sum_{i=1}^{n+1} w_i * x_i}{\\sum_{i=1}^{n+1} w_i}  | \\\\\n",
        "\n",
        "                      &\\leq  | \\frac{\\sum_{i=1}^n w_i * x_i}{\\sum_{i=1}^{n+1} w_i} -          \\frac{\\sum_{i=1}^{n+1} w_i * x_i}{\\sum_{i=1}^{n+1} w_i}|\\\\\n",
        "                      &= |\\frac{\\sum_{i=1}^n w_i * x_i - \\sum_{i=1}^{n+1} w_i * x_i}{\\sum_{i=1}^{n+1} w_i}|\\\\\n",
        "                      &= |\\frac{w_{n+1}*x_{n+1}}{\\sum_{i=1}^{n+1} w_i}|\\\\\n",
        "                      &= |\\frac{w_{n+1}*x_{n+1}}{\\sum_{i=1}^n w_i + w_{n+1}}|\\\\\n",
        "                      &= |\\frac{w_{n+1}*x_{n+1}}{\\text{suma}(w) + w_{n+1}}|\\\\\n",
        "                      &\\leq |\\frac{4*10}{\\text{suma}(w) + 4}|\\\\\n",
        "                      &= |\\frac{40}{\\text{suma}(w) + 4}|\n",
        "\\end{align}\n",
        "$$\n",
        "Por lo tanto, podemos ver que la sensibilidad de dicha función depende de la suma de todos los ´weights´ (de la base de datos original, es decir, de aquella que aún no tiene ningún registro nuevo añadido), del peso y rating del nuevo registro $w_{n+1}$ y $x_{n+1}$, respectivamente. En general, es de esperar que dicha sensibilidad no sea muy grande si la ponderación del rating de cada persona es baja en relación a la suma de todos los pesos. Como el peso va entre 1 y 4 y el rating entre 1 y 10, podemos incluso ir más allá en la demostración. Por lo tanto, dicha función no es diferencialmente privada, porque si el analista sabe la sensibilidad local del dataset, puede inferir cosas de él (en el caso de la sensibilidad local)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHiLR-N2q_4j"
      },
      "source": [
        "## Question 4 (9 points)\n",
        "\n",
        "As we saw in class, even though local sensitivity gives us a better upper bound than global sensitivity, we cannot directly use it with the mechanisms we have seen (e.g. laplace).\n",
        "\n",
        "We will implement the Propose-Test-Release method for calculating a private weighted average of `barbie_ratings`. In order to do that, follow the next steps:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fFteTtrtni"
      },
      "source": [
        "1. Implement a function to compute the *Maximum Local Sensitivity* at distance k:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKs1MklosPSc"
      },
      "outputs": [],
      "source": [
        "def ls_at_distance(target_ub, weight_ub, W, k):\n",
        "    \"\"\"\n",
        "        Parameters:\n",
        "            target_ub (int): Upper bound of the target values\n",
        "            weight_ub (int): Upper bound of the weights\n",
        "            W (int): Total sum of weights in the original dataset\n",
        "            k (int): Number of steps away (number of changes)\n",
        "        Returns:\n",
        "            Local sensitivity at distance k\n",
        "    \"\"\"\n",
        "    #el máximo peso añadido será k veces el peso máixmo:\n",
        "    maximo_peso_añadido = k * weight_ub\n",
        "    #como ya demostramos en la parte anterior,\n",
        "    #el promedio máximo posible si agregamos k valores máximos será:\n",
        "    cambio_superior = (target_ub * maximo_peso_añadido) / (W.sum() + maximo_peso_añadido)\n",
        "    #el promedio mínimo posible si agregamos k valores mínimos será 0, porque\n",
        "    #el mínimo de los pesos es cero, y por ende el promedio sería 0, así como \n",
        "    #el denominador:\n",
        "    cambio_inferior = 0\n",
        "\n",
        "    #y asumiendo promedio actual entre 0 y target_ub, evaluamos máximas diferencias\n",
        "    delta_superior = abs(target_ub - cambio_superior)\n",
        "    delta_inferior = abs(0 - cambio_inferior)\n",
        "\n",
        "    return max(delta_superior, delta_inferior)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SDcHKLuvTaF"
      },
      "source": [
        "2. Implement a function to find the minimum number of steps to achieve a local sensitivity of at least $b$:\n",
        "\n",
        "*Hint: Start by trying with $k=0$, and increment $k$ until the threshold of $b$ is achieved*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfnuYIV5vhl1"
      },
      "outputs": [],
      "source": [
        "def dist_to_high_ls(target_ub, weight_ub, W, b):\n",
        "    \"\"\"\n",
        "        Parameters:\n",
        "            target_ub (int): The upper bound of the target column\n",
        "            weight_ub (int): The upper bound of the weight column\n",
        "            W (int): The sum of the weights of the origin dataframe\n",
        "            b (float): The proposed bound on local sensitivity\n",
        "        Returns:\n",
        "            The minimum number of steps to achieve a local sensitivity of at least `b`\n",
        "    \"\"\"\n",
        "    #como dice el hint, primero inicializamos k como cero para ir incrementandolo\n",
        "    #hasta que alcanzamos el valor b.\n",
        "    k = 0\n",
        "    while True:\n",
        "        ls = ls_at_distance(target_ub, weight_ub, W, k)\n",
        "        if ls >= b:\n",
        "            return k\n",
        "        k += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6onKa_xpwv4Y"
      },
      "source": [
        "3. Implement the PTR version of weighted average:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGTMpdIow4CA"
      },
      "outputs": [],
      "source": [
        "def ptr_weighted_avg(data, weights, data_ub, weight_ub, b, epsilon, delta):\n",
        "    \"\"\"\n",
        "        Parameters:\n",
        "            data    (pd.Series): The data to average, in this case, the ratings\n",
        "            weights (pd.Series): The weights to calculate the average\n",
        "            data_ub (int): The upper bound of the target column\n",
        "            weight_ub (int): The upper bound of the weight column\n",
        "            b (float): The proposed bound on local sensitivity\n",
        "            epsilon, delta: The level of privacy\n",
        "        Returns:\n",
        "            The private weighted average using PTR\n",
        "    \"\"\"\n",
        "    data_clipped = data.clip(upper=data_ub)\n",
        "    k = dist_to_high_ls(data_ub, weight_ub, denominador, b)\n",
        "\n",
        "\n",
        "    weights_clipped = weights.clip(upper=weight_ub)\n",
        "\n",
        "    numerador = (data_clipped * weights_clipped).sum()\n",
        "    denominador = weights_clipped.sum()\n",
        "    avg = numerador / denominador\n",
        "\n",
        "\n",
        "    beta = epsilon / (2 * np.log(2 / delta))\n",
        "    smooth_sens = b * np.exp(-beta * k)\n",
        "    noise = laplace_noise(scale=smooth_sens / epsilon)\n",
        "\n",
        "    return avg + noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Dp0Qhf3N1Uxa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.464530557116332"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ptr_weighted_avg(ratings, weights, u, wu, 0.02, 1.0, 10e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Ionxsn1N3h"
      },
      "source": [
        "## Question 5 (4 points)\n",
        "\n",
        "The following code plots the relative errors (against the real answer) of global sensitivity and PTR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GufhM8ZHuWVE"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epsilon = 1.0\n",
        "delta = 10e-6\n",
        "b = 0.05\n",
        "\n",
        "gs_errors = []\n",
        "ptr_errors = []\n",
        "\n",
        "real_avg = weighted_avg(ratings, weights)\n",
        "\n",
        "for i in range(200):\n",
        "    ptr_result = ptr_weighted_avg(ratings, weights, u, wu, b, epsilon, delta)\n",
        "\n",
        "    gs_result = gs_weighted_avg(ratings, weights, u, wu, epsilon)\n",
        "    gs_errors.append(pct_error(real_avg, gs_result))\n",
        "\n",
        "    if ptr_result is None:\n",
        "        continue\n",
        "\n",
        "    ptr_errors.append(pct_error(real_avg, ptr_result))\n",
        "\n",
        "_, bins, _ = plt.hist(gs_errors, label='Global sensitivity');\n",
        "plt.hist(ptr_errors, alpha=.7, label='PTR', bins=bins);\n",
        "plt.xlabel('Percent Error')\n",
        "plt.ylabel('Number of Trials')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMPnM7gdLAkY"
      },
      "source": [
        "1. Compare the accuracies of both methods. Which one is better? Explain how the plot helps justifying your analysis.\n",
        "2. What can you say about the parameter $b$, in terms of the usability of the PTR method? How does this aspect compare to the global sensitivity method?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwtW31scitA8"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0XC9fkQLuDr"
      },
      "source": [
        "## Question 6 (3 points)\n",
        "\n",
        "Now, we will implement the weighted average using the Smooth Sensitivity framework.\n",
        "\n",
        "First, implement `smooth_ls_at_distance`, which calculates the local sensitivity at distance $k$, smoothed out by an exponential factor of $e^{-\\beta k}$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9r_SI9iFMXnf"
      },
      "outputs": [],
      "source": [
        "def smooth_ls_at_distance(data_ub, weight_ub, W, k, beta):\n",
        "    \"\"\"\n",
        "        Parameters:\n",
        "            data_ub (int): The upper bound of the target column\n",
        "            weight_ub (int): The upper bound of the weight column\n",
        "            W (int): The sum of the weights of the origin dataframe\n",
        "            k (int): The number of steps away from the origin dataframe\n",
        "            beta (float): The smooth factor\n",
        "        Returns:\n",
        "            The smoothed local sensitivity at distance k\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gva0jUgjPJwL"
      },
      "source": [
        "## Question 7 (2 points)\n",
        "\n",
        "1. What does the following graph shows?\n",
        "2. What information can we infer from this plot to help us implement a weighted average using smooth sensitivity?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7QU4ETSM3Iw"
      },
      "outputs": [],
      "source": [
        "beta = 0.05\n",
        "\n",
        "r = [smooth_ls_at_distance(u, wu, weights.sum(), k, beta) for k in range(0, 200)]\n",
        "\n",
        "plt.plot(r);\n",
        "plt.xlabel('Value of k')\n",
        "plt.ylabel('Smoothed-out Local Sensitivity');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20VBDfy0Pamu"
      },
      "source": [
        "## Question 8 (6 points)\n",
        "\n",
        "Implement the query using Smooth Sensitivity:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzrMdiL1i7uM"
      },
      "outputs": [],
      "source": [
        "def ss_weighted_avg(data, weights, data_ub, weight_ub, epsilon, delta):\n",
        "    \"\"\"\n",
        "        Parameters:\n",
        "            data    (pd.Series): The data to average\n",
        "            weights (pd.Series): The weights to calculate the average\n",
        "            data_ub (int): The upper bound of the target column\n",
        "            weight_ub (int): The upper bound of the weight column\n",
        "            epsilon, delta: The level of privacy\n",
        "        Returns:\n",
        "            The private weighted average using Smooth Sensitivity\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "ss_weighted_avg(ratings, weights, u, wu, epsilon, delta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB4YF9CwP5Yq"
      },
      "source": [
        "## Question 9 (4 points)\n",
        "\n",
        "The following code plots the relative errors (against the real answer) of global sensitivity and Smooth Sensitivity:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzYZFumTCkL0"
      },
      "outputs": [],
      "source": [
        "gs_results  = [\n",
        "    pct_error(weighted_avg(ratings, weights),\n",
        "    gs_weighted_avg(ratings, weights, u, wu, epsilon)) for i in range(100)]\n",
        "ptr_results = [\n",
        "    pct_error(weighted_avg(ratings, weights),\n",
        "    ss_weighted_avg(ratings, weights, u, wu, epsilon, delta)) for i in range(100)]\n",
        "\n",
        "_, bins, _ = plt.hist(gs_results, label='Global sensitivity');\n",
        "plt.hist(ptr_results, alpha=.7, label='Smooth sensitivity', bins=bins);\n",
        "plt.xlabel('Percent Error')\n",
        "plt.ylabel('Number of Trials')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3xqJxi4i_DQ"
      },
      "source": [
        "1. Compare the accuracies of both methods. Explain how the plot helps justifying your analysis.\n",
        "2. What disadvantage has this method when comparing it with the global sensitivity approach?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U42lvix6jwZi"
      },
      "source": [
        "## Question 10 (6 points)\n",
        "\n",
        "Let us define a function that receives $k$ results, computed from **disjoint** sets of data, and calculates the clipped (by $l$ and $u$) average between them as follows:\n",
        "\n",
        "$$\n",
        "g_{l,u}(x) = \\frac{\\sum^k_{i=1} \\mathsf{clip}(x_i, l, u)}{k}\n",
        "$$\n",
        "\n",
        "where $x$ is a vector that represent the average of each disjoint set of data.\n",
        "\n",
        "**Calculate the global sensitivity of $g_{l,u}$.**\n",
        "\n",
        "*Hint: Use the fact that the computations x_i are disjoint*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU0FB4pDRoi7"
      },
      "source": [
        "Complete:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "|g_{l,u}(x) - g_{l,u}(x')| &= \\dots \\\\\n",
        "                           &= \\dots \\\\\n",
        "                           &\\leq \\dots\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg6VA4u3SJif"
      },
      "source": [
        "## Question 11 (6 points)\n",
        "\n",
        "Implement the Sample & Aggregate framework for weighted averages, using $g$ as your aggregation function.\n",
        "\n",
        "*Hint: Use the function `np.array_split` to divide the dataframe in $k$ chunks.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZId4rP0SDoE5"
      },
      "outputs": [],
      "source": [
        "def sa_weighted_avg(data, weights, k, l, u, epsilon):\n",
        "    \"\"\"\n",
        "        Parameters:\n",
        "            data    (pd.Series): The data to average\n",
        "            weights (pd.Series): The weights to calculate the average\n",
        "            k (int): The number of chunks\n",
        "            l, u (int): The clipping parameters for dividing the partial averages\n",
        "            epsilon (float): The privacy budget\n",
        "        Returns:\n",
        "            The private weighted average using Sample & Aggregate\n",
        "    \"\"\"\n",
        "    raise NotImplementedError()\n",
        "\n",
        "sa_weighted_avg(ratings, weights, 200, 2, 8, epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgCfyxqGS1f-"
      },
      "source": [
        "## Question 12 (4 points)\n",
        "\n",
        "The following code plots the relative errors (against the real answer) of global sensitivity and Smooth Sensitivity:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iupzp8gYGKLa"
      },
      "outputs": [],
      "source": [
        "gs_results  = [\n",
        "    pct_error(weighted_avg(ratings, weights),\n",
        "    gs_weighted_avg(ratings, weights, u, wu, epsilon)) for i in range(100)]\n",
        "ptr_results = [\n",
        "    pct_error(weighted_avg(ratings, weights),\n",
        "    sa_weighted_avg(ratings, weights, 200, 2, 8, epsilon)) for i in range(100)]\n",
        "\n",
        "_, bins, _ = plt.hist(gs_results, label='Global sensitivity');\n",
        "plt.hist(ptr_results, alpha=.7, label='Sam. & Agg.', bins=bins);\n",
        "plt.xlabel('Percent Error')\n",
        "plt.ylabel('Number of Trials')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcCCCoemTAuV"
      },
      "source": [
        "1. Compare the accuracies of both methods. Explain how the plot helps justifying your analysis.\n",
        "2. We used bounds of $(2,8)$ as clipping parameters for the intermediate averages. Do you think those are reasonable bounds? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADVCfNJSTBfB"
      },
      "source": [
        "YOUR ANSWER"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
